{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A full 1D analysis using the low-level Gammapy API**\n",
    "\n",
    "**Objective: Performing a full spectral anaysis of the point source [PKS 2155-304](http://tevcat.uchicago.edu/?mode=1&showsrc=90)**\n",
    "\n",
    "Here we demonstrate the data reduction and spectral fitting for a point like source, using the [reflected regions background estimation](https://docs.gammapy.org/1.2/user-guide/makers/reflected.html?highlight=reflected) method.\n",
    "\n",
    "In practice, we have to:\n",
    "- Prepare the **data access and selection**\n",
    "  - Create a `~gammapy.data.DataStore` poiting to the relevant data \n",
    "  - Apply an observation selection to produce a list of observations, a `~gammapy.data.Observations` object.\n",
    "- Set up the **analyis parameters**\n",
    "  - Define the [reconstructed energy](https://docs.gammapy.org/1.2/user-guide/references.html#term-Reco-Energy) axis and [true energy](https://docs.gammapy.org/1.2/user-guide/references.html#term-True-Energy) axis using the `~gammapy.maps.MapAxis` object\n",
    "  - Define the spatial geometry\n",
    "  - Define the [exclusion mask](https://docs.gammapy.org/1.2/tutorials/api/mask_maps.html)\n",
    "  - Choose the correct `~gammapy.datasets.Dataset` type and define it\n",
    "- Do the **data reduction**\n",
    "  - Create the necessary makers : \n",
    "    - the spectrum dataset maker : `~gammapy.makers.SpectrumDatasetMaker`\n",
    "    - the reflected regions finder: either `~gammapy.makers.ReflectedRegionsFinder` or `~gammapy.makers.WobbleRegionsFinder`\n",
    "    - the background maker, here a `~gammapy.makers.ReflectedRegionsBackgroundMaker`\n",
    "    - and usually the safe range maker : `~gammapy.makers.SafeMaskMaker`\n",
    "  - Perform the data reduction loop. And for every observation:\n",
    "    - Apply the makers sequentially to produce the current `~gammapy.datasets.SpectrumDatasetOnOff`\n",
    "    - Stack it on the target one.\n",
    "- Make **the modeling and fitting**\n",
    "  - Define the `~gammapy.modeling.models.SkyModel` to fit the data. Being this a spectral analysis, the `SkyModel` is completely defined by a  `~gammapy.modeling.models.SpectralModel` (no spatial information is required)\n",
    "  - Create a `~gammapy.modeling.Fit` object and run it to fit the model parameters\n",
    "  - Apply a `~gammapy.estimators.FluxPointsEstimator` to compute flux points for the spectral part of the fit.\n",
    "\n",
    "## Setup\n",
    "First, we setup the analysis by performing required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from gammapy.maps import WcsGeom, MapAxis, RegionGeom\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    PointSpatialModel,\n",
    "    SkyModel,\n",
    "    Models,\n",
    "    FoVBackgroundModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    EBLAbsorptionNormSpectralModel\n",
    ")\n",
    "from gammapy.makers import SafeMaskMaker, SpectrumDatasetMaker, ReflectedRegionsFinder, ReflectedRegionsBackgroundMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.datasets import MapDataset, FluxPointsDataset, Datasets, SpectrumDataset\n",
    "from scipy.stats import chi2\n",
    "from gammapy.stats.utils import ts_to_sigma\n",
    "from gammapy.catalog import SourceCatalog4FGL\n",
    "\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from regions import CircleSkyRegion\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.visualization import plot_spectrum_datasets_off_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very optional set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the documentation: the [HowTo](https://docs.gammapy.org/1.2/user-guide/howto.html) section, the search bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The logging level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()    \n",
    "log = logging.getLogger(\"1Danalysis\")\n",
    "log.setLevel(logging.WARNING) #INFO, WARNING, DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppression of the astropy warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astropy.io.fits.verify import VerifyWarning\n",
    "# import warnings\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter('ignore', VerifyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Progress bar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the external library `tqdm` is installed\n",
    "from gammapy.utils import pbar\n",
    "pbar.SHOW_PROGRESS_BAR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the datastore and selecting observations\n",
    "\n",
    "We first use the `~gammapy.data.DataStore` object to access the observations we want to analyse, here the H.E.S.S. DL3 DR1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/hess-dl3-dr1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = SkyCoord(329.71693844, -30.22558846, unit=u.deg, frame=\"icrs\")\n",
    "pos.icrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define an observation filter to select only the relevant observations. \n",
    "Here we use a cone search that we define with a python dict.\n",
    "\n",
    "We then filter the `ObservationTable` with `~gammapy.data.ObservationTable.select_sky_circle()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_table_filtered = data_store.obs_table.select_sky_circle(center=pos, radius=2 * u.deg)\n",
    "obs_ids = obs_table_filtered[\"OBS_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to apply more complex filtering options, you can use the `~gammapy.data.ObservationTable.select_observations()` method instead. This provides the freedom of selecting observations based on a sky circle, time period or parameter (e.g. Zenith angle) range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the relevant observations by passing their `obs_id` to the`~gammapy.data.DataStore.get_observations()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data_store.get_observations(obs_ids)\n",
    "print(f\"Number of selected observations : {len(observations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restrict the analysis to the [July 2006 flaring event](https://ui.adsabs.harvard.edu/abs/2009A%26A...502..749A/abstract) using `gammapy.data.Observations.select_time()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = Time(\n",
    "    [\"2006-07-29T20:30\", \"2006-07-30T20:30\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = observations.select_time(time_interval)\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = observations[12]\n",
    "obs.events.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.aeff.peek();\n",
    "obs.edisp.peek();\n",
    "obs.psf.peek();\n",
    "obs.bkg.peek();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing reduced datasets geometry\n",
    "\n",
    "Now we define the [reconstructed](https://docs.gammapy.org/0.20/userguide/references.html#term-Reco-Energy) and [true](https://docs.gammapy.org/0.20/userguide/references.html#term-True-Energy) energy axes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    0.1, 40, nbin=10, per_decade=True, unit=\"TeV\", name=\"energy\"\n",
    ")\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    0.05, 100, nbin=20, per_decade=True, unit=\"TeV\", name=\"energy_true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a ON region to extract the spectrum, and create the analysis geometry using the `RegionGeom` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_region_radius = Angle(\"0.11 deg\")\n",
    "on_region = CircleSkyRegion(center=pos, radius=on_region_radius)\n",
    "\n",
    "geom = RegionGeom.create(region=on_region, axes=[energy_axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the dataset used for this 1D analysis using this geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_empty = SpectrumDataset.create(\n",
    "    geom=geom, energy_axis_true=energy_axis_true\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create exclusion mask\n",
    "\n",
    "To perform the spectral analysis we must mask all the gamma ray emission in the analysis region, which would otherwise bias the background estimation. Here we are analyzing an extra-Galactic source, which is isolated and would not require a priori an exclusion mask. However, for illustration purpose, we choose a mask of 0.5 deg to the North of the blazar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_region = CircleSkyRegion(\n",
    "    center=SkyCoord(329.71, -29, unit=\"deg\", frame=\"icrs\"),\n",
    "    radius=0.3 * u.deg,\n",
    ")\n",
    "\n",
    "skydir = pos.icrs\n",
    "exgeom = WcsGeom.create(width=5*u.deg, binsz=0.02, skydir=skydir, proj=\"TAN\", frame=\"icrs\"\n",
    ")\n",
    "\n",
    "exclusion_mask = ~exgeom.region_mask([exclusion_region])\n",
    "exclusion_mask.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction\n",
    "\n",
    "### Create the maker classes to be used\n",
    "We first initialize the `Maker` objects that will take care of the data reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `~gammapy.makers.SpectrumDatasetMaker`creates a `SpectrumDataset` for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=True, selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PS: zoom on the parameter `containment_correction'**\n",
    "\n",
    "In the used data release, the IRFs are computed for a \"full containment\" response, ie all the signal for an objet falls into the analysis Region of Interest (there is no PSF leakage).\n",
    "\n",
    "However, here for the 1D analysis with a `RegionGeom' of 0.11 deg, a part of the signal lies outside the selection region. Then, the IRFs, and mainly the collection area, should be corrected from the PSF leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `~gammapy.makers.ReflectedRegionsBackgroundMaker` appends a background estimate (based on the [reflected regions](https://docs.gammapy.org/1.0.1/user-guide/makers/reflected.html?highlight=reflected) method) to an input `SpectrumDataset`, converting it into a `SpectrumDatasetOnOff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_maker = ReflectedRegionsBackgroundMaker(exclusion_mask=exclusion_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `ReflectedRegionsBackgroundMaker` defines the OFF regions by rotating the ON region around the pointing position.\n",
    "\n",
    "PS: if you need to apply more complex criteria to your OFF regions selection (e.g. an energy dependent rad-max cut / configure the number of OFF regions, etc) you can additionally pass to the `ReflectedRegionsBackgroundMaker` an instance of `~gammapy.makers.WobbleRegionsFinder` (see [this tutorial](https://docs.gammapy.org/1.2|/user-guide/makers/reflected.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a `~gammapy.makers.SafeMaskMaker` instance, which is responsible of selecting the safe data range (in energy and space) in which the data can be used.\n",
    "In this example we only use the method `aeff-default`, which reads the safe energy threshold specified in the DL3 FITS files. For other available method see the documentation of the [SafeMaskMaker](https://docs.gammapy.org/1.0.1/api/gammapy.makers.SafeMaskMaker.html?highlight=safemaskmaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_mask_masker = SafeMaskMaker(methods=[\"aeff-default\"])\n",
    "# safe_mask_masker = SafeMaskMaker(methods=[\"aeff-max\"], aeff_percent=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the data reduction loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment the datasets are not stacked, but appended into a `Datasets` object (that basically contains a list of datasets). That's because we want to produce diagnostic plots such as the cumulative source significance as a function of the observation livetime. The stacking will be performed later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "datasets = Datasets()\n",
    "for observation in observations:\n",
    "    # First a spectrum dataset with the same geometry as the reference empty one is filled with \n",
    "    # the data and IRFs\n",
    "    dataset = dataset_maker.run(dataset_empty.copy(name=str(observation.obs_id)), observation)\n",
    "    # Reflected regions background estimation\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    # The data quality cut is applied\n",
    "    dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n",
    "    # The resulting dataset is appended to the list\n",
    "    datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = exclusion_mask.plot();\n",
    "plot_spectrum_datasets_off_regions(ax=ax, datasets=datasets);\n",
    "on_region.to_pixel(ax.wcs).plot(ax=ax, color=\"black\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table = datasets.info_table(cumulative=True)\n",
    "info_table\n",
    "# info_table[:5]\n",
    "# display(info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot(221)\n",
    "ax1.plot(\n",
    "    info_table[\"livetime\"].to(\"h\"), info_table[\"excess\"], marker=\"o\", ls=\"none\"\n",
    ")\n",
    "ax1.set_xlabel(\"Livetime [h]\")\n",
    "ax1.set_ylabel(\"Excess\");\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "ax2.plot(\n",
    "    info_table[\"livetime\"].to(\"h\"),\n",
    "    info_table[\"sqrt_ts\"],\n",
    "    marker=\"o\",\n",
    "    ls=\"none\",\n",
    ")\n",
    "ax2.set_xlabel(\"Livetime [h]\")\n",
    "ax2.set_ylabel(\"Sqrt(TS)\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset to disc using `~gammapy.datasets.Datasets.write()` method.\n",
    "\n",
    "PS: The OGIP format is used (PHA, ARF, RMF, BKG, [see](https://gamma-astro-data-formats.readthedocs.io/en/latest/spectra/ogip/index.html) here for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"pks-joint-dataset.yaml\"\n",
    "datasets.write(filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cat pks-joint-dataset.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting we stack the `Datasets` into a single `SpectrumDatasetOnOff`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stacked\n",
    "stacked = datasets.stack_reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fitting\n",
    "\n",
    "In this section we fit a spectral model to the data. We can try to answer the following questions:\n",
    "- What is the significance of the detected source?\n",
    "- What is the best spectral shape to describe the spectrum of the source? \n",
    "\n",
    "In particular, we can use the [likelihood ratio test](https://docs.gammapy.org/1.2/user-guide/stats/index.html#estimating-ts) (see also the associated HowTo) to compare three different hypotheses:\n",
    "- H0: Background only (no source)\n",
    "- H1: Background + source described by a power law model\n",
    "- H2: Background + source described by a power law model with exponential cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the quantity $-2\\ln\\mathcal(L)$ for the background-only model (null hypothesis) can be simply computed as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wstat_0 = stacked.stat_sum()\n",
    "print(Wstat_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the background has been estimated using the reflected regions method, here $-2\\ln\\mathcal(L)$ corresponds to the so-called [Wstat](https://docs.gammapy.org/0.20/userguide/references.html#term-WStat) fit statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the model residuals for the H0 hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.plot_residuals_spectral();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the residuals show a clear positive feature indicating that a source is missing in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **H1**\n",
    "We now add a source defined by a power law spectrum to the model.\n",
    "\n",
    "Here we also consider [EBL absorption](https://docs.gammapy.org/1.2/user-guide/model-gallery/spectral/plot_absorbed.html?highlight=ebl). To get the list of EBL models, you can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gammapy.modeling.models.spectral as spectral\n",
    "# spectral.EBL_DATA_BUILTIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_pl = PowerLawSpectralModel()\n",
    "redshift = 0.116\n",
    "ebl = EBLAbsorptionNormSpectralModel.read_builtin(\"finke\", redshift=redshift)\n",
    "spectral_model_1 = spectral_model_pl * ebl\n",
    "\n",
    "pks_model_1 = SkyModel(spectral_model=spectral_model_1,\n",
    "                    name=\"pks_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks_model_1.parameters.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.models = [pks_model_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit1 = Fit(optimize_opts={\"print_level\": 1})\n",
    "result1 = fit1.run(datasets=[stacked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.success\n",
    "# print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.models.to_parameters_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wstat_1 = result1.total_stat\n",
    "delta_ts = Wstat_0-Wstat_1\n",
    "df = len(result1.models.parameters.free_parameters.names)\n",
    "sigma = ts_to_sigma(delta_ts, df=df)\n",
    "print(f\"The delta_ts  of H1 vs H0: {delta_ts:.3f}, that gives a p-value of {chi2.sf(delta_ts, df)}\")\n",
    "print(f\"Converting this to a significance gives: {sigma:.3f} \\u03C3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_spectrum, ax_residuals = stacked.plot_fit()\n",
    "# ax_spectrum.set_xlim(0.2, 70)\n",
    "# stacked.plot_masks(ax=ax_spectrum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute flux points for the H1 model assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_edges = np.logspace(-1, 1.6, 12)*u.TeV\n",
    "fpe = FluxPointsEstimator(energy_edges=energy_edges, source=pks_model_1.name, selection_optional=[\"ul\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flux_points = fpe.run(datasets=[stacked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = spectral_model_pl.plot(energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", label=\"intrinsic\", color=\"blue\")\n",
    "spectral_model_1.plot(ax=ax, energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", label=\"absorbed\", color=\"red\")\n",
    "spectral_model_1.plot_error(ax=ax, energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", facecolor=\"red\")\n",
    "flux_points.plot(ax=ax, sed_type=\"e2dnde\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **H2**\n",
    "\n",
    "We now estimate the significance for the presence of an exponential cutoff in the source spectrum, again taking into account the EBL absorption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_ecpl = ExpCutoffPowerLawSpectralModel()\n",
    "redshift = 0.116\n",
    "spectral_model_2 = spectral_model_ecpl * ebl\n",
    "\n",
    "pks_model_2 = SkyModel(spectral_model=spectral_model_2,\n",
    "                    name=\"pks_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks_model_2.parameters.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.models = [pks_model_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit2 = Fit(optimize_opts={\"print_level\": 1})\n",
    "result2 = fit2.run(datasets=[stacked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.models.to_parameters_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wstat_2 = result2.total_stat\n",
    "delta_ts = Wstat_1-Wstat_2\n",
    "df = len(result2.models.parameters.free_parameters.names)-len(result1.models.parameters.free_parameters.names)\n",
    "sigma = ts_to_sigma(delta_ts, df=df)\n",
    "print(f\"The delta_ts  of H2 vs H1: {delta_ts:.3f}, that gives a p-value of {chi2.sf(delta_ts, df)}\")\n",
    "print(f\"Converting this to a significance gives: {sigma:.3f} \\u03C3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully detected a cutoff in the observed spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_spectrum, ax_residuals = stacked.plot_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the fit has coverged correctly, it is always a good idea to inspect the likelihood profile for the free model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat = result2.total_stat\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4))\n",
    "\n",
    "for ax, par in zip(axes, pks_model_2.parameters.free_parameters):\n",
    "    par.scan_n_values = 25\n",
    "\n",
    "    profile = fit2.stat_profile(datasets=[stacked], parameter=par)\n",
    "    ax.plot(profile[f\"{pks_model_2.name}.spectral.{par.name}_scan\"], profile[\"stat_scan\"] - total_stat)\n",
    "    ax.set_xlabel(f\"{par.unit}\")\n",
    "    ax.set_ylabel(\"Delta TS\")\n",
    "    ax.set_title(f\"{par.name}: {par.value:.1e} +- {par.error:.1e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the flux points for the H2 hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flux_points = fpe.run(datasets=[stacked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = spectral_model_ecpl.plot(energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", label=\"intrinsic\", color=\"blue\")\n",
    "spectral_model_2.plot(ax=ax, energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", label=\"absorbed\", color=\"red\")\n",
    "spectral_model_2.plot_error(ax=ax, energy_bounds=[0.1,20]*u.TeV, sed_type=\"e2dnde\", facecolor=\"red\")\n",
    "flux_points.plot(ax=ax, sed_type=\"e2dnde\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_points.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "\n",
    "## Beginner\n",
    "- Select and analyze observations of PSK 2155-304 during its steady state \n",
    "- Try other models, eg: log-parabola, broken power law, etc. See the model gallery for a list of available models: https://docs.gammapy.org/1.2/user-guide/model-gallery/index.html\n",
    "- What is the impact of changing the OFF regions criteria (their number, shape, finding method)? \n",
    "- Try to repeat the fit using a different minimizer. By default Gammapy uses Minuit, but it also supports the Sherpa and Scipy backends.\n",
    "\n",
    "## Advanced\n",
    "- Create a gammapy.estimators.FluxPointsDataset with the flux points you have computed for the stacked dataset and fit the flux points again with one of the spectral models. How does the result compare to the best fit model, that was directly fitted to the counts data?\n",
    "- Compute a 2-dimensional likelihood contour to estimate the correlation between the fitted parameters (e.g. the spectral index and cutoff). (Tutorial reference: https://docs.gammapy.org/1.2/tutorials/api/fitting.html)\n",
    "- Repeat exercise on the Crab runs available in GAMMAPY_DATA. Alternatively, if you have access to CTA DC1 simulated data, repeat on your favourite source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gammapy-dev)",
   "language": "python",
   "name": "gammapy-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
